# MMEE ‚Äî Multimedia Event Extraction

> **End-to-End Multimodal Event Extraction from Images + Text**  
> Repository for a planned publication with the working title:  
> *Faithful Multimodal Event Extraction via Concept Bottlenecks*  

MMEE is designed to detect **event mentions**, classify **event types**, and extract **arguments/roles** by fusing **visual and textual evidence**.  

‚ö†Ô∏è **Note**: This repository currently contains **partial code** for multimodal event extraction tasks.  
- The full pipeline is **not runnable yet** and will be updated soon.  
- It does **not include datasets** or **pre-trained model weights**.  

---

## ‚ú® Features (planned)
- Multimodal fusion of **image and text representations**  
- Event mention detection  
- Event type classification  
- Argument/role extraction  
- Integration with **concept bottleneck models** for interpretability  

---
## üì¨ Contact
For questions:  
**Hasan Alam** ‚Äî [hasan.alam@dfki.de](mailto:hasan.alam@dfki.de)  

---
