# MMEE â€” Multimedia Event Extraction

> **End-to-End Multimodal Event Extraction from Images + Text**  
> Repository for a planned publication with the working title:  
> *Faithful Multimodal Event Extraction via Concept Bottlenecks*  

MMEE is designed to detect **event mentions**, classify **event types**, and extract **arguments/roles** by fusing **visual and textual evidence**.  

**Note**: This repository currently contains code for multimodal event extraction tasks.  
- Shared_Cross_Modal_IE contains the files and instructions to run the pipeline for Cross modal Event Extraction

---

## âœ¨ Features
- Multimodal fusion of **image and text representations**  
- Event mention detection  
- Event type classification  
- Argument/role extraction  

---
## ðŸ“¬ Contact
For questions:  
**Hasan Alam** â€” [hasan.alam@dfki.de](mailto:hasan.alam@dfki.de)  

---
